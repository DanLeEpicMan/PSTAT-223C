{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d1bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.3\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "from typing import Callable\n",
    "\n",
    "rng = np.random.default_rng(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8006bd88",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f4232",
   "metadata": {},
   "source": [
    "*Note: I had originally written this code unparallelized, so the run times for Question 1 are abysmally long. The code works fine, but ideally I would parallelize everything. Questions 2 and 3 are parallelized, and under ideal conditions I would rewrite this code, however my Week 4 has been extremely busy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297947d8",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "For a general Ito process $dX_t = a(t, X_t) dt + b(t, X_t) dW_t$, we recall that the Milstein scheme is given by\n",
    "\n",
    "$$\n",
    "\\hat{X}_{n+1} = \\hat{X}_n + a(t_n, \\hat{X}_n) \\Delta t + b(t_n, \\hat{X}_n) \\Delta W_{n+1} + b_x (t_n, \\hat{X}_n) b(t_n, \\hat{X}_n) \\left( \\frac{(\\Delta W_{n+1})^2 - \\Delta t}{2} \\right)\n",
    "$$\n",
    "Where $\\Delta W_{n} \\overset{\\mathrm{iid}}{\\sim} \\mathcal{N}(0, \\Delta t)$\n",
    "\n",
    "Therefore, for $dV_t = \\kappa (\\theta - V_t) dt + \\eta \\sqrt{V_t} dW_t$ we have that its Milstein scheme is given by\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "        \\hat{V}_{n+1} &= \\hat{V}_n + \\kappa (\\theta - \\hat{V}_n) \\Delta t + \\eta \\sqrt{\\hat{V}_n} \\Delta W_{n+1} + \\frac{\\eta}{2 \\sqrt{\\hat{V}_n}} \\cdot \\eta \\sqrt{\\hat{V}_n} \\left( \\frac{(\\Delta W_{n+1})^2 - \\Delta t}{2} \\right) \\\\\n",
    "        &= \\hat{V}_n + \\kappa (\\theta - \\hat{V}_n) \\Delta t + \\eta \\sqrt{\\hat{V}_n} \\Delta W_{n+1} + \\frac{\\eta^2}{4} \\left( (\\Delta W_{n+1})^2 - \\Delta t \\right)\n",
    "    \\end{align*} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c96c8",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a37f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_euler_path(\n",
    "    *,\n",
    "    dt: float,\n",
    "    T: float,\n",
    "    r: float,\n",
    "    kappa: float,\n",
    "    theta: float,\n",
    "    eta: float,\n",
    "    s0: float,\n",
    "    v0: float,\n",
    "    rho: float\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    Simulates one path by performing Euler-Mayurama for both St, Vt.\n",
    "    Returns a tuple (St, Vt).\n",
    "\n",
    "    Note that this assumes that `T = k * dt` for some integer `k`.\n",
    "    Thus, this simulates `k` steps.\n",
    "    '''\n",
    "    total_runs = int(T / dt)\n",
    "    s_path = np.empty(total_runs)\n",
    "    v_path = np.empty(total_runs)\n",
    "    s_path[0], v_path[0] = s0, v0\n",
    "\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "    # simulate each path (skip first step since that's done above)\n",
    "    for i in range(1, total_runs):\n",
    "        # first, correlate the brownian motions\n",
    "        b1, b2 = rng.normal(loc=0, scale=sqrt_dt, size=2)\n",
    "        w1, w2 = b1, rho * b1 + np.sqrt(1 - rho**2) * b2\n",
    "\n",
    "        if v_path[i-1] < 0: # prevent errors from negative v_p.\n",
    "            v_path[i-1] = 0\n",
    "        # simulate s\n",
    "        s_path[i] = s_path[i-1] + r * s_path[i-1] * dt + s_path[i-1] * np.sqrt(v_path[i-1]) * w1\n",
    "\n",
    "        # simulate v (using euler)\n",
    "        v_path[i] = v_path[i-1] + kappa * (theta - v_path[i-1]) * dt + eta * np.sqrt(v_path[i-1]) * w2\n",
    "\n",
    "    return s_path, v_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f866c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_milstein_path(\n",
    "    *,\n",
    "    dt: float,\n",
    "    T: float,\n",
    "    r: float,\n",
    "    kappa: float,\n",
    "    theta: float,\n",
    "    eta: float,\n",
    "    s0: float,\n",
    "    v0: float,\n",
    "    rho: float\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    Simulates one path by performing Euler-Mayurama for St, Milstein for Vt.\n",
    "    Returns a tuple (St, Vt).\n",
    "\n",
    "    Note that this assumes that `T = k * dt` for some integer `k`.\n",
    "    '''\n",
    "    total_runs = int(T / dt)\n",
    "    s_path = np.empty(total_runs)\n",
    "    v_path = np.empty(total_runs)\n",
    "    s_path[0], v_path[0] = s0, v0\n",
    "\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "    # simulate each path (skip first step since that's done above)\n",
    "    for i in range(1, total_runs):\n",
    "        # first, correlate the brownian motions\n",
    "        b1, b2 = rng.normal(loc=0, scale=sqrt_dt, size=2)\n",
    "        w1, w2 = b1, rho * b1 + np.sqrt(1 - rho**2) * b2\n",
    "\n",
    "        if v_path[i-1] < 0: # prevent errors from negative v_p.\n",
    "            v_path[i-1] = 0\n",
    "        # simulate s\n",
    "        s_path[i] = s_path[i-1] + r * s_path[i-1] * dt + s_path[i-1] * np.sqrt(v_path[i-1]) * w1\n",
    "\n",
    "        # simulate v (using milstein)\n",
    "        v_path[i] = v_path[i-1] + kappa * (theta - v_path[i-1]) * dt + eta * np.sqrt(v_path[i-1]) * w2 + (eta**2 / 4) * (w2**2 - dt)\n",
    "\n",
    "    return s_path, v_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fadf10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mc_samples(\n",
    "    M: int,\n",
    "    method: Callable[..., tuple[np.ndarray, np.ndarray]],\n",
    "    **kwargs\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Generate `M` samples using `method`. \n",
    "    Returns a 2d array, where each row is a simulation of `St`.\n",
    "    \n",
    "    `kwargs` are passed into `method`. Note that `dt = 1 / path_size`.\n",
    "    '''\n",
    "    s_paths = np.array([method(**kwargs)[0] for _ in range(M)])\n",
    "    \n",
    "    return s_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea1d7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euler-Euler scheme with r = 1\n",
      "\n",
      "Time elapsed: 91.17 seconds\n",
      "\n",
      "Put Option: Simulation with r=1\n",
      "95% confidence interval: [15.41, 15.67]\n",
      "99% confidence interval: [15.37, 15.71]\n",
      "\n",
      "Asian Option: Simulation with r=1\n",
      "95% confidence interval: [19.15, 19.57]\n",
      "99% confidence interval: [19.09, 19.64]\n",
      "\n",
      "Euler-Milstein scheme with r=1\n",
      "Time elapsed: 125.78 seconds\n",
      "\n",
      "Put Option: Simulation with r=1\n",
      "95% confidence interval: [15.39, 15.64]\n",
      "99% confidence interval: [15.35, 15.68]\n",
      "\n",
      "Asian Option: Simulation with r=1\n",
      "95% confidence interval: [19.01, 19.43]\n",
      "99% confidence interval: [18.95, 19.49]\n",
      "-----------------------------------\n",
      "Euler-Euler scheme with r = 2\n",
      "\n",
      "Time elapsed: 237.45 seconds\n",
      "\n",
      "Put Option: Simulation with r=2\n",
      "95% confidence interval: [15.37, 15.63]\n",
      "99% confidence interval: [15.33, 15.67]\n",
      "\n",
      "Asian Option: Simulation with r=2\n",
      "95% confidence interval: [18.95, 19.36]\n",
      "99% confidence interval: [18.88, 19.43]\n",
      "\n",
      "Euler-Milstein scheme with r=2\n",
      "Time elapsed: 254.67 seconds\n",
      "\n",
      "Put Option: Simulation with r=2\n",
      "95% confidence interval: [15.52, 15.77]\n",
      "99% confidence interval: [15.48, 15.81]\n",
      "\n",
      "Asian Option: Simulation with r=2\n",
      "95% confidence interval: [19.08, 19.50]\n",
      "99% confidence interval: [19.01, 19.56]\n",
      "-----------------------------------\n",
      "Euler-Euler scheme with r = 3\n",
      "\n",
      "Time elapsed: 497.00 seconds\n",
      "\n",
      "Put Option: Simulation with r=3\n",
      "95% confidence interval: [15.46, 15.71]\n",
      "99% confidence interval: [15.42, 15.75]\n",
      "\n",
      "Asian Option: Simulation with r=3\n",
      "95% confidence interval: [19.09, 19.51]\n",
      "99% confidence interval: [19.02, 19.57]\n",
      "\n",
      "Euler-Milstein scheme with r=3\n",
      "Time elapsed: 489.54 seconds\n",
      "\n",
      "Put Option: Simulation with r=3\n",
      "95% confidence interval: [15.47, 15.73]\n",
      "99% confidence interval: [15.43, 15.77]\n",
      "\n",
      "Asian Option: Simulation with r=3\n",
      "95% confidence interval: [19.28, 19.70]\n",
      "99% confidence interval: [19.21, 19.77]\n",
      "-----------------------------------\n",
      "Euler-Euler scheme with r = 4\n",
      "\n",
      "Time elapsed: 676.39 seconds\n",
      "\n",
      "Put Option: Simulation with r=4\n",
      "95% confidence interval: [15.49, 15.75]\n",
      "99% confidence interval: [15.45, 15.79]\n",
      "\n",
      "Asian Option: Simulation with r=4\n",
      "95% confidence interval: [19.20, 19.62]\n",
      "99% confidence interval: [19.13, 19.68]\n",
      "\n",
      "Euler-Milstein scheme with r=4\n",
      "Time elapsed: 667.30 seconds\n",
      "\n",
      "Put Option: Simulation with r=4\n",
      "95% confidence interval: [15.45, 15.71]\n",
      "99% confidence interval: [15.41, 15.75]\n",
      "\n",
      "Asian Option: Simulation with r=4\n",
      "95% confidence interval: [19.10, 19.51]\n",
      "99% confidence interval: [19.03, 19.58]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# now compute desired statistics for each simulation\n",
    "\n",
    "# parameters\n",
    "M       = int(1e5)\n",
    "K       = 100\n",
    "Nt      = 52\n",
    "T       = 1\n",
    "r       = 0.05\n",
    "kappa   = 1\n",
    "theta   = 0.2\n",
    "eta     = 0.5\n",
    "rho     = -0.4\n",
    "s0      = 100\n",
    "v0      = 0.25\n",
    "\n",
    "def print_summary_stats(\n",
    "    paths: np.ndarray,\n",
    "    exponent_term: int\n",
    "):\n",
    "    '''\n",
    "    Given `paths`, print the summary statistics for each option\n",
    "    '''\n",
    "    # compute put option samples\n",
    "    put_samples: np.ndarray = np.exp(-r * T) * (K - paths[:, -1])\n",
    "    put_samples[put_samples < 0] = 0\n",
    "\n",
    "    put_mean = put_samples.mean()\n",
    "    put_width = put_samples.std(mean=put_mean) / np.sqrt(len(put_samples))\n",
    "    print(\n",
    "        f'\\nPut Option: Simulation with r={exponent_term}',\n",
    "        f'95% confidence interval: [{put_mean - 1.96 * put_width:.2f}, {put_mean + 1.96 * put_width:.2f}]',\n",
    "        f'99% confidence interval: [{put_mean - 2.57 * put_width:.2f}, {put_mean + 2.57 * put_width:.2f}]',\n",
    "        sep='\\n'\n",
    "    )\n",
    "\n",
    "    # compute asian option samples\n",
    "    asian_samples: np.ndarray = np.exp(-r * T) * (paths[:, -1] - paths[:, ::2**exponent_term].mean())\n",
    "    asian_samples[asian_samples < 0] = 0\n",
    "\n",
    "    asian_mean = asian_samples.mean()\n",
    "    asian_width = asian_samples.std(mean=asian_mean) / np.sqrt(len(asian_samples))\n",
    "    print(\n",
    "        f'\\nAsian Option: Simulation with r={exponent_term}',\n",
    "        f'95% confidence interval: [{asian_mean - 1.96 * asian_width:.2f}, {asian_mean + 1.96 * asian_width:.2f}]',\n",
    "        f'99% confidence interval: [{asian_mean - 2.57 * asian_width:.2f}, {asian_mean + 2.57 * asian_width:.2f}]',\n",
    "        sep='\\n'\n",
    "    )\n",
    "\n",
    "for exponent_term in range(1, 5):\n",
    "    # start with euler-euler simulations\n",
    "    print(f'Euler-Euler scheme with r = {exponent_term}\\n')\n",
    "    ee_start_time = time.time()\n",
    "    ee_s_paths = generate_mc_samples(\n",
    "        M=M, \n",
    "        method=euler_euler_path,\n",
    "        dt=1 / (52 * 2 ** exponent_term),\n",
    "        T=1,\n",
    "        r=r,\n",
    "        kappa=kappa,\n",
    "        theta=theta,\n",
    "        eta=eta,\n",
    "        rho=rho,\n",
    "        s0=s0,\n",
    "        v0=v0\n",
    "    )\n",
    "    ee_end_time = time.time()\n",
    "    print(f'Time elapsed: {ee_end_time - ee_start_time:.2f} seconds')\n",
    "    print_summary_stats(\n",
    "        ee_s_paths,\n",
    "        exponent_term=exponent_term\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f'\\nEuler-Milstein scheme with r={exponent_term}')\n",
    "    em_start_time = time.time()\n",
    "    em_s_paths = generate_mc_samples(\n",
    "        M=M, \n",
    "        method=euler_milstein_path,\n",
    "        dt=1 / (52 * 2 ** exponent_term),\n",
    "        T=1,\n",
    "        r=r,\n",
    "        kappa=kappa,\n",
    "        theta=theta,\n",
    "        eta=eta,\n",
    "        rho=rho,\n",
    "        s0=s0,\n",
    "        v0=v0\n",
    "    )\n",
    "    em_end_time = time.time()\n",
    "    print(f'Time elapsed: {em_end_time - em_start_time:.2f} seconds')\n",
    "    print_summary_stats(\n",
    "        em_s_paths,\n",
    "        exponent_term=exponent_term\n",
    "    )\n",
    "    print('-----------------------------------')\n",
    "\n",
    "    # compute euler-euler put option samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f05300",
   "metadata": {},
   "source": [
    "## (c)\n",
    "\n",
    "The first observation to make is that the Euler-Euler (EE) and Euler-Milstein (EM) schemes take roughly the same amount of time to compute sample paths. While EE is faster for small $r$, this gap closes as $r$ increases.\n",
    "\n",
    "Secondly, as $\\Delta t \\to 0$ the convergence is very slow. The accuracy for the Put option of EE improves to 5 cents then stays roughly constant. For the Asian option EE, the range stays roughly at 40 cents each iteration.\n",
    "\n",
    "For EM, the convergence is also slow. The Asian 95 interval width is 42 cents for $r=1$, improving to 41 cents for $r=4$.\n",
    "\n",
    "Lastly, as for how the two methods compare to each other, they perform roughly the same each iteration, where the width of the 95 intervals don't change by very much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf20d3",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e71e3",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbce67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "T = 2\n",
    "r = 0.05\n",
    "mu = 0.25\n",
    "sig = 0.25\n",
    "lam = 6\n",
    "zeta = 50\n",
    "gamma = -1.5\n",
    "dt = 0.02\n",
    "M = 10000\n",
    "\n",
    "rng = np.random.default_rng(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01bda3",
   "metadata": {},
   "source": [
    "First, we compute the dynamics of $X_t$. We have that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    dS_t &= \\mu S_t dt + \\sigma S_t dW_t - S_{t-} dJ_t \\\\\n",
    "    dB_t &= r B_t dt \\\\\n",
    "    dX_t &= \\pi X_t \\frac{dS}{S_t} + (1 - \\pi) X_t \\frac{dB_t}{B_t}\n",
    "\\end{align*}\n",
    "$$\n",
    "Therefore\n",
    "$$\n",
    "    dX_t = X_t (\\pi \\mu + (1 - \\pi) r) dt + \\pi X_t \\sigma dW_t - \\frac{S_{t-}}{S_t} dJ_t\n",
    "$$\n",
    "Where $J_t = \\sum_{i=1}^{N_t} e^{Y_j} - 1$, $N_t \\sim \\mathrm{Pois}(\\lambda t)$, $Y_j \\overset{\\mathrm{iid}}{\\sim} \\mathrm{Exp}(\\zeta)$. To accomplish this, we use the following scheme\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{X}_{n+1} &= \\hat{X}_n + \\hat{X}_n (\\pi\\mu + (1 - \\pi) r) \\Delta t + \\sigma \\pi \\hat{X}_n \\Delta W_{n+1} + (1 - e^{Y_n})(\\pi \\hat{X}_n) \\Delta N_n \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Where $\\Delta N_n \\overset{\\mathrm{iid}}{\\sim} \\mathrm{Bernoulli}(\\lambda \\Delta t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "396bc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_x(x0: float = 1.0, pi: float = 0.5, dW: np.ndarray | None = None) -> np.ndarray:\n",
    "    '''\n",
    "    Returns M sample paths of X_t. By default, `X0 = 1, pi = 0.5`\n",
    "    '''\n",
    "    points = int(T / dt) + 1\n",
    "    x_path = np.empty((M, points))\n",
    "    x_path[:, 0] = x0\n",
    "\n",
    "    dW = dW if dW is not None else rng.normal(scale=np.sqrt(dt), size=(M, points))\n",
    "    dN = rng.binomial(n=1, p=dt * lam, size=(M, points))\n",
    "    # convert dN into dJ by multiplying by 1 - exp(Y)\n",
    "    \n",
    "    Y  = rng.exponential(1/zeta, size=(M, points)) \n",
    "    # definitely not the most efficient way to do this, but much quicker than python for loops (i checked)\n",
    "    dJ = dN * (1 - np.exp(Y))\n",
    "\n",
    "    for i in range(1, points):\n",
    "        x_i = x_path[:, i-1]\n",
    "        x_path[:, i] = x_i + x_i * (pi * mu + (1 - pi) * r) * dt + sig * pi * x_i * dW[:, i-1] - pi * x_i * dJ[:, i-1]\n",
    "        x_path[x_path[:, i] < 0, i] = 0\n",
    "\n",
    "    return x_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef656dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC Average with Pi = 0.5, X0 = 50, S0 = 100: -0.559851\n",
      "95 Confidence Interval: [-0.565760, -0.553942]\n"
     ]
    }
   ],
   "source": [
    "def compute_utility_samples(\n",
    "    pi: float = 0.5,\n",
    "    x0 = 1, \n",
    "    dW: np.ndarray | None = None,\n",
    "    samps: int = M\n",
    ") -> np.ndarray:\n",
    "    x_samples = np.array([simulate_x(pi=pi, x0=x0, dW=dW) for _ in range(samps)])\n",
    "    utility_samples = x_samples[:, -1]**gamma / gamma\n",
    "\n",
    "    return utility_samples\n",
    "\n",
    "dW = rng.normal(scale=np.sqrt(dt), size=(M, int(T / dt) + 1))\n",
    "samps = compute_utility_samples(dW=dW, samps=1000)\n",
    "samps_avg = samps.mean()\n",
    "samps_std = samps.std(mean=samps_avg)\n",
    "print(\n",
    "    f'MC Average with Pi = 0.5, X0 = 1: {samps_avg:.6f}',\n",
    "    f'95 Confidence Interval: [{samps_avg - 1.96 * samps_std / np.sqrt(len(samps)):.6f}, {samps_avg + 1.96 * samps_std / np.sqrt(len(samps)):.6f}]',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb0caf",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "pis = np.linspace(start=0, stop=1, num=21) # 0, 0.05, 0.1, ...\n",
    "\n",
    "x_pi_sims = [compute_utility_samples(pi=pi, dW=dW, samps=500) for pi in pis] # lowering my samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cc9a93bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utility_sims = [arr.mean() for arr in x_pi_sims]\n",
    "\n",
    "sns.lineplot(x=pis, y=utility_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3a173",
   "metadata": {},
   "source": [
    "*I've been debugging my code for hours and I have absolutely no clue why this graph is my final answer. I know it is wrong, but I cannot figure out what exactly is wrong. I've checked my code extensively and my implementations are fine (only issue I noticed is simulating too many RVs).*\n",
    "\n",
    "*At this point I've given up, and I'll accept that this is wrong. I'll probably come back to this in the future, but I am extremely busy this week, so I can't spend any more time on this question :(*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de16b7",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2231520",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a48ee",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "We define the payoff\n",
    "\n",
    "$$\n",
    "\\Phi (\\{X_t\\}_{[0, 0.5]}) = \\begin{cases}\n",
    "1 &\\text{if } X_t \\in [15, 25] \\forall \\, 0 \\leq t \\leq 0.5 \\\\\n",
    "0 &\\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And set $dX_t = 0.04 X_t dt + 0.4 X_{t}^{0.8} dW_t, X_0 = 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3c91647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 0.5876007080078125 seconds\n",
      "95% Confidence Interval for Corridor Option: [0.8075, 0.8124]\n"
     ]
    }
   ],
   "source": [
    "num_points = int(0.5 / 0.01) + 1\n",
    "M = int(1e5)\n",
    "\n",
    "standard_start_time = time.time()\n",
    "samples = np.empty((M, num_points))\n",
    "samples[:, 0] = 20\n",
    "dW = rng.normal(loc=0, scale=0.1, size=(M, num_points-1))\n",
    "\n",
    "for i in range(num_points - 1):\n",
    "    samples[:, i+1] = samples[:, i] + 0.04 * samples[:, i] * 0.01 + 0.4 * samples[:, i]**0.8 * dW[:, i]\n",
    "\n",
    "in_corridor: np.ndarray = ((samples.max(axis=1) <= 25) & (samples.min(axis=1) >= 15)).astype(np.int8)\n",
    "\n",
    "standard_end_time = time.time()\n",
    "standard_time_elapsed = standard_end_time - standard_start_time\n",
    "\n",
    "mc_mean = in_corridor.mean()\n",
    "mc_se = in_corridor.std(mean=mc_mean) / np.sqrt(M)\n",
    "\n",
    "print(f'Time Elapsed: {standard_time_elapsed} seconds')\n",
    "print(f'95% Confidence Interval for Corridor Option: [{mc_mean - 1.96 * mc_se:.4f}, {mc_mean + 1.96 * mc_se:.4f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622d6d4",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ab7e6",
   "metadata": {},
   "source": [
    "For the antithetic sampling method, we take $$-dW_t$$ and add these to our estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "347df267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Antithetic Confidence Interval for Corridor Option: [0.8082, 0.8117]\n",
      "Regular MC SE: 0.0012407642548042718\n",
      "Antithetic MC SE: 0.0008772821621348516\n"
     ]
    }
   ],
   "source": [
    "antithetic_time_start = time.time()\n",
    "\n",
    "antithetic_samples = np.empty((M, num_points))\n",
    "antithetic_samples[:, 0] = 20\n",
    "antithetic_dW = -dW\n",
    "\n",
    "for i in range(num_points - 1):\n",
    "    antithetic_samples[:, i+1] = antithetic_samples[:, i] + 0.04 * antithetic_samples[:, i] * 0.01 + 0.4 * antithetic_samples[:, i]**0.8 * antithetic_dW[:, i]\n",
    "\n",
    "final_antithetic_samples = np.concatenate([samples, antithetic_samples])\n",
    "\n",
    "antithetic_in_corridor: np.ndarray = ((final_antithetic_samples.max(axis=1) <= 25) & (final_antithetic_samples.min(axis=1) >= 15)).astype(np.int8)\n",
    "\n",
    "antithetic_time_stop = time.time()\n",
    "antithetic_time_elapsed = antithetic_time_stop - antithetic_time_start\n",
    "\n",
    "antithetic_mc_mean = antithetic_in_corridor.mean()\n",
    "antithetic_mc_se = antithetic_in_corridor.std(mean=antithetic_mc_mean) / np.sqrt(2 * M)\n",
    "\n",
    "print(f'95% Antithetic Confidence Interval for Corridor Option: [{antithetic_mc_mean - 1.96 * antithetic_mc_se:.4f}, {antithetic_mc_mean + 1.96 * antithetic_mc_se:.4f}]')\n",
    "print(f'Regular MC SE: {mc_se}', f'Antithetic MC SE: {antithetic_mc_se}', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b9973",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a241f8b",
   "metadata": {},
   "source": [
    "I will use the step sizes $h_1 = 0.01$, $h_2 = 0.02$, $h_3 = 0.0025$. In doing so, the scheme in (a) becomes the cheap one, and we're incorporating benefits of faster schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80e5a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = 50000\n",
    "h1 = 0.01\n",
    "N2 = 15000\n",
    "h2 = 0.005\n",
    "N3 = 5000\n",
    "h3 = 0.0025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a9d3e",
   "metadata": {},
   "source": [
    "For ease, we recall $dX_t = 0.04 X_t dt + 0.4 X_{t}^{0.8} dW_t, X_0 = 20$.\n",
    "\n",
    "Set $G_i$ to be scheme $i$ (i.e. using step size $h_i$). Then we are evaluating\n",
    "\n",
    "$$\n",
    "    \\mathbb{E} [G_0] + \\mathbb{E} [G_1 - G_0] + \\mathbb{E} [G_2 - G_1]\n",
    "$$\n",
    "\n",
    "Where we simulate each item under the expectation independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "24ad5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmc_start_time = time.time()\n",
    "\n",
    "# coarse scheme\n",
    "coarse_points = int(0.5 / h1) + 1\n",
    "coarse_x = np.empty((N1, coarse_points))\n",
    "coarse_x[:, 0] = 20\n",
    "coarse_dW = np.sqrt(h1) * rng.normal(size=(N1, coarse_points - 1))\n",
    "\n",
    "for i in range(coarse_points - 1):\n",
    "    prev_x = coarse_x[:, i]\n",
    "    coarse_x[:, i+1] = prev_x + 0.04 * prev_x * h1 + 0.4 * prev_x**0.8 * coarse_dW[:, i]\n",
    "\n",
    "coarse_payoffs: np.ndarray = ((coarse_x.max(axis=1) <= 25) & (coarse_x.min(axis=1) >= 15)).astype(np.int8)\n",
    "\n",
    "# moderate scheme\n",
    "moderate_points = int(0.5 / h2) + 1\n",
    "moderate_x = np.empty((N2, moderate_points))\n",
    "moderate_x[:, 0] = 20\n",
    "moderate_bm = rng.normal(size=(N2, moderate_points - 1))\n",
    "moderate_dW = np.sqrt(h2) * moderate_bm\n",
    "\n",
    "for i in range(moderate_points - 1):\n",
    "    prev_x = moderate_x[:, i]\n",
    "    moderate_x[:, i+1] = prev_x + 0.04 * prev_x * h2 + 0.4 * prev_x**0.8 * moderate_dW[:, i]\n",
    "\n",
    "moderate_level1_payoffs: np.ndarray = ((moderate_x.max(axis=1) <= 25) & (moderate_x.min(axis=1) >= 15)).astype(np.int8)\n",
    "\n",
    "# use moderate RVs for coarse RVs\n",
    "coarse_with_moderate_x = np.empty((N2, coarse_points))\n",
    "coarse_with_moderate_x[:, 0] = 20\n",
    "coarse_with_moderate_dW = np.sqrt(h2 / 2) * (moderate_bm[:, ::2] + moderate_bm[:, 1::2])\n",
    "\n",
    "for i in range(coarse_points - 1):\n",
    "    prev_x = coarse_with_moderate_x[:, i]\n",
    "    coarse_with_moderate_x[:, i+1] = prev_x + 0.04 * prev_x * h1 + 0.4 * prev_x**0.8 * coarse_with_moderate_dW[:, i]\n",
    "\n",
    "moderate_level0_payoffs: np.ndarray = ((coarse_with_moderate_x.max(axis=1) <= 25) & (coarse_with_moderate_x.min(axis=1) >= 15)).astype(np.int8)\n",
    "\n",
    "moderate_bias = moderate_level1_payoffs - moderate_level1_payoffs\n",
    "\n",
    "# fine scheme\n",
    "fine_points = int(0.5 / h3) + 1\n",
    "fine_x = np.empty((N3, fine_points))\n",
    "fine_x[:, 0] = 20\n",
    "fine_bm = rng.normal(size=(N3, fine_points - 1))\n",
    "fine_dW = np.sqrt(h3) * fine_bm\n",
    "\n",
    "for i in range(fine_points - 1):\n",
    "    prev_x = fine_x[:, i]\n",
    "    fine_x[:, i+1] = prev_x + 0.04 * prev_x * h3 + 0.4 * prev_x**0.8 * fine_dW[:, i]\n",
    "\n",
    "fine_level2_payoffs: np.ndarray = ((fine_x.max(axis=1) <= 25) & (fine_x.min(axis=1) >= 15)).astype(np.int8)\n",
    "\n",
    "# coarse scheme with fine BM\n",
    "moderate_with_fine_x = np.empty((N3, moderate_points))\n",
    "moderate_with_fine_x[:, 0] = 20\n",
    "moderate_with_fine_dW = np.sqrt(h2 / 2) * (fine_bm[:, ::2] + fine_bm[:, 1::2])\n",
    "\n",
    "for i in range(moderate_points - 1):\n",
    "    prev_x = moderate_with_fine_x[:, i]\n",
    "    moderate_with_fine_x[:, i+1] = prev_x + 0.04 * prev_x * h2 + 0.4 * prev_x**0.8 * moderate_with_fine_dW[:, i]\n",
    "\n",
    "fine_level1_payoffs: np.ndarray = ((moderate_with_fine_x.max(axis=1) <= 25) & (moderate_with_fine_x.min(axis=1) >= 15)).astype(np.int8)\n",
    "\n",
    "fine_bias = fine_level2_payoffs - fine_level1_payoffs\n",
    "\n",
    "mlmc_end_time = time.time()\n",
    "mlc_time_elapsed = mlmc_end_time - mlmc_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03464ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% MLMC Confidence Interval: [0.7987142847888962, 0.8068057152111039]\n",
      "Standard SE: 0.0012407642548042718, Time Elapsed: 0.5876007080078125\n",
      "Antithetic SE: 0.0008772821621348516, Time Elapsed: 0.6238477230072021\n",
      "MLMC SE: 0.002064140413828478, Time Elapsed: 0.4974968433380127\n"
     ]
    }
   ],
   "source": [
    "# compute monte carlo estimates and se\n",
    "# note that due to independence, se of final estimate is just sum of the se's \n",
    "mlmc_mean = coarse_payoffs.mean() + moderate_bias.mean() + fine_bias.mean()\n",
    "mlmc_se = np.sqrt(coarse_payoffs.var() / N1 + moderate_bias.var() / N2 + fine_bias.var() / N3)\n",
    "\n",
    "print(f'95% MLMC Confidence Interval: [{mlmc_mean - 1.96 * mlmc_se}, {mlmc_mean + 1.96 * mlmc_se}]')\n",
    "print(\n",
    "    f'Standard SE: {mc_se}, Time Elapsed: {standard_time_elapsed}',\n",
    "    f'Antithetic SE: {antithetic_mc_se}, Time Elapsed: {antithetic_time_elapsed}',\n",
    "    f'MLMC SE: {mlmc_se}, Time Elapsed: {mlc_time_elapsed}',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd1eab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Change for Standard Error: 66.3604%\n",
      "Percent Change for Time Elapsed: -15.3342%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percent Change for Standard Error: {100 * (mlmc_se - mc_se) / mc_se:.4f}%')\n",
    "print(f'Percent Change for Time Elapsed: {100 * (mlc_time_elapsed - standard_time_elapsed) / standard_time_elapsed:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb99716",
   "metadata": {},
   "source": [
    "Compared to Standard Monte Carlo, we see that MLMC achieves 66.4% more error while running 15.3% faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
